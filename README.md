<h1 align="center">Hi 👋, I'm Amer Al-Jabri</h1>
<h3 align="center">A passionate Full Stack developer from Yemen</h3>


<p align="left"> <a href="https://twitter.com/ameraljabri8080" target="blank"><img src="https://img.shields.io/twitter/follow/ameraljabri8080?logo=twitter&style=for-the-badge" alt="ameraljabri8080" /></a> </p>

- 🌱 I’m currently learning **ERPNext customization**

- 👨‍💻 All of my projects are available at [https://github.com/AmerAljabri/AmerAljabri](https://github.com/AmerAljabri/AmerAljabri)

- 💬 Ask me about **Flutter,Python,ASP.NET Framework**

- 📫 How to reach me **ameraljabri180@gmail.com**

<h3 align="left">Connect with me:</h3>
<p align="left">
<a href="https://twitter.com/ameraljabri8080" target="blank"><img align="center" src="https://raw.githubusercontent.com/rahuldkjain/github-profile-readme-generator/master/src/images/icons/Social/twitter.svg" alt="ameraljabri8080" height="30" width="40" /></a>
</p>

<h3 align="left">Languages and Tools:</h3>
<p align="left"> <a href="https://getbootstrap.com" target="_blank" rel="noreferrer"> <img src="https://raw.githubusercontent.com/devicons/devicon/master/icons/bootstrap/bootstrap-plain-wordmark.svg" alt="bootstrap" width="40" height="40"/> </a> <a href="https://www.w3schools.com/cpp/" target="_blank" rel="noreferrer"> <img src="https://raw.githubusercontent.com/devicons/devicon/master/icons/cplusplus/cplusplus-original.svg" alt="cplusplus" width="40" height="40"/> </a> <a href="https://www.w3schools.com/cs/" target="_blank" rel="noreferrer"> <img src="https://raw.githubusercontent.com/devicons/devicon/master/icons/csharp/csharp-original.svg" alt="csharp" width="40" height="40"/> </a> <a href="https://www.w3schools.com/css/" target="_blank" rel="noreferrer"> <img src="https://raw.githubusercontent.com/devicons/devicon/master/icons/css3/css3-original-wordmark.svg" alt="css3" width="40" height="40"/> </a> <a href="https://dart.dev" target="_blank" rel="noreferrer"> <img src="https://www.vectorlogo.zone/logos/dartlang/dartlang-icon.svg" alt="dart" width="40" height="40"/> </a> <a href="https://firebase.google.com/" target="_blank" rel="noreferrer"> <img src="https://www.vectorlogo.zone/logos/firebase/firebase-icon.svg" alt="firebase" width="40" height="40"/> </a> <a href="https://flutter.dev" target="_blank" rel="noreferrer"> <img src="https://www.vectorlogo.zone/logos/flutterio/flutterio-icon.svg" alt="flutter" width="40" height="40"/> </a> <a href="https://www.w3.org/html/" target="_blank" rel="noreferrer"> <img src="https://raw.githubusercontent.com/devicons/devicon/master/icons/html5/html5-original-wordmark.svg" alt="html5" width="40" height="40"/> </a> <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript" target="_blank" rel="noreferrer"> <img src="https://raw.githubusercontent.com/devicons/devicon/master/icons/javascript/javascript-original.svg" alt="javascript" width="40" height="40"/> </a> <a href="https://laravel.com/" target="_blank" rel="noreferrer"> <img src="https://raw.githubusercontent.com/devicons/devicon/master/icons/laravel/laravel-plain-wordmark.svg" alt="laravel" width="40" height="40"/> </a> <a href="https://www.linux.org/" target="_blank" rel="noreferrer"> <img src="https://raw.githubusercontent.com/devicons/devicon/master/icons/linux/linux-original.svg" alt="linux" width="40" height="40"/> </a> <a href="https://www.microsoft.com/en-us/sql-server" target="_blank" rel="noreferrer"> <img src="https://www.svgrepo.com/show/303229/microsoft-sql-server-logo.svg" alt="mssql" width="40" height="40"/> </a> <a href="https://www.mysql.com/" target="_blank" rel="noreferrer"> <img src="https://raw.githubusercontent.com/devicons/devicon/master/icons/mysql/mysql-original-wordmark.svg" alt="mysql" width="40" height="40"/> </a> <a href="https://www.oracle.com/" target="_blank" rel="noreferrer"> <img src="https://raw.githubusercontent.com/devicons/devicon/master/icons/oracle/oracle-original.svg" alt="oracle" width="40" height="40"/> </a> <a href="https://www.php.net" target="_blank" rel="noreferrer"> <img src="https://raw.githubusercontent.com/devicons/devicon/master/icons/php/php-original.svg" alt="php" width="40" height="40"/> </a> <a href="https://www.postgresql.org" target="_blank" rel="noreferrer"> <img src="https://raw.githubusercontent.com/devicons/devicon/master/icons/postgresql/postgresql-original-wordmark.svg" alt="postgresql" width="40" height="40"/> </a> <a href="https://postman.com" target="_blank" rel="noreferrer"> <img src="https://www.vectorlogo.zone/logos/getpostman/getpostman-icon.svg" alt="postman" width="40" height="40"/> </a> <a href="https://www.python.org" target="_blank" rel="noreferrer"> <img src="https://raw.githubusercontent.com/devicons/devicon/master/icons/python/python-original.svg" alt="python" width="40" height="40"/> </a> <a href="https://www.sqlite.org/" target="_blank" rel="noreferrer"> <img src="https://www.vectorlogo.zone/logos/sqlite/sqlite-icon.svg" alt="sqlite" width="40" height="40"/> </a> <a href="https://unity.com/" target="_blank" rel="noreferrer"> <img src="https://www.vectorlogo.zone/logos/unity3d/unity3d-icon.svg" alt="unity" width="40" height="40"/> </a> </p>

<p><img align="left" src="https://github-readme-stats.vercel.app/api/top-langs?username=ameraljabri&show_icons=true&locale=en&layout=compact" alt="ameraljabri" /></p>

<p>&nbsp;<img align="center" src="https://github-readme-stats.vercel.app/api?username=ameraljabri&show_icons=true&locale=en" alt="ameraljabri" /></p>

<p><img align="center" src="https://github-readme-streak-stats.herokuapp.com/?user=ameraljabri&" alt="ameraljabri" /></p>


<p align="left"> <img src="https://komarev.com/ghpvc/?username=ameraljabri&label=Profile%20views&color=0e75b6&style=flat" alt="ameraljabri" /> </p>

<p align="left"> <a href="https://github.com/ryo-ma/github-profile-trophy"><img src="https://github-profile-trophy.vercel.app/?username=ameraljabri" alt="ameraljabri" /></a> </p>


```

Important: Use one-hot encoding for categorical variables.
```python
myData = pd.get_dummies(myData, drop_first=True)
```

Prepare the data:  Neural networks train much (much, much) quicker on normalized datasets.  
It's also important to reserve part of the dataset as a test set.  Unfortunately this dataset is very small, so we can't really afford to set aside a validation set.  Let's reserve 20% of our data as a test set.
```python
myData = (myData - np.min(myData))/(np.max(myData) - np.min(myData))
x = myData.drop('target', axis=1)
y = myData['target']
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=.2, random_state=2)
```



# Scikit-Learn Models
Scikit-learn enables us to quickly build and train models to a dataset.  Each of these models has a fit() method, as well as predict() and score().  This uniformity will allow us to make an ensemble voting classifier without much effort.

```python
lin_model = LogisticRegression(solver='lbfgs')
lin_model.fit(x_train, y_train)
print("Linear Model Accuracy: ", lin_model.score(x_test, y_test))

knn_model = KNeighborsClassifier()
knn_model.fit(x_train, y_train)
print("K Nearest Neighbor Model Accuracy: ", knn_model.score(x_test, y_test))

svm_model = SVC(gamma='auto')
svm_model.fit(x_train, y_train)
print("Support Vector Machine Model Accuracy: ", svm_model.score(x_test, y_test))

nb_model = GaussianNB()
nb_model.fit(x_train, y_train)
print("Naive Bayes Model Accuracy: ", nb_model.score(x_test, y_test))

tree_model = DecisionTreeClassifier()
tree_model.fit(x_train, y_train)
print("Decision Tree Model Accuracy: ", tree_model.score(x_test, y_test))

forest_model = RandomForestClassifier(n_estimators=100)
forest_model.fit(x_train, y_train)
print("Random Forest Model Accuracy: ", forest_model.score(x_test, y_test))
```

Outputs will vary (quite a bit, actually!) depending on random seeds.  One run produced the following output:
```
Linear Model Accuracy:  0.8524590163934426
K Nearest Neighbor Model Accuracy:  0.8360655737704918
Support Vector Machine Model Accuracy:  0.8524590163934426
Naive Bayes Model Accuracy:  0.8688524590163934
Decision Tree Model Accuracy:  0.7540983606557377
Random Forest Model Accuracy:  0.8360655737704918
```


# Deep Learning Model

We'll build a simple model with three fully-connected layers of 100 units, 100 units, 10 units, and ReLU activations.  This last layer feeds into a single unit with sigmoid activation.  The best choices for loss function for a classification task are typically binary_crossentropy and categorical_hinge.  Categorical_hinge is a direct generalization of SVM, and happens to work well here, so that's what we'll go with.
```python
model = Sequential()
model.add(Dense(100, input_shape=(19,)))
model.add(ReLU())
model.add(Dense(100))
model.add(ReLU())
model.add(Dense(10))
model.add(ReLU())
model.add(Dense(1, activation='sigmoid'))
model.summary()

model.compile(optimizer='Adam', loss='categorical_hinge', metrics=['accuracy'])
```


Train the model:
```python
model.fit(X_train, Y_train, epochs=15)
```


And check how it does on our test set:
```python
y_predicted = (model.predict(X_test) >= 0.5)

conf_mat = confusion_matrix(Y_test, y_predicted)
print(conf_mat)
total = sum(sum(conf_mat))
sensitivity = conf_mat[0, 0]/(conf_mat[0, 0] + conf_mat[1, 0])
specificity = conf_mat[1, 1]/(conf_mat[1, 1] + conf_mat[0, 1])
accuracy = (conf_mat[0, 0] + conf_mat[1, 1])/total

print('specificity : ', specificity)
print('sensitivity : ', sensitivity)
print('accuracy : ', accuracy)
```

Here's the console output:
```
[[23  4]
 [ 3 31]]
specificity :  0.8857142857142857
sensitivity :  0.8846153846153846
accuracy :  0.8852459016393442

```

Some analysis:  The confusion matrix is interpreted as follows:  Upon running our learned model on the test set, the model came up with 23 true negatives and 31 true positives.  There were 4 false positives and 3 false negatives, leading to specificity of 31/35 and sensitivity of 23/26.  It must be noted that since the test set is so small (61 samples), every right or wrong answer alters the accuracy score by about 1.5%.  This volatility is very undesirable and heavily rewards overfitting to the test set - again, something which could be avoided if we had enough data for a validation set.

Since this model predicts something as important as heart disease, we're much happier with false positives than with false negatives.  There are several ways to decrease the number of false negatives.  Recall that this neural network has a last-layer sigmoid, so the activation of the final neuron is somewhere between 0 and 1.  By default we round to the nearest integer to obtain a prediction, so that (for example) if some input to the network leads to a final neuron activation of 0.6, we predict heart disease, and if some input leads to a final activation of 0.4, we predict no heart disease.  Instead of rounding to the nearest integer (i.e. returning (final_activation >= 0.5) ), we could change the cutoff point to some other value.  Consider the following variant:

```python
y_predicted = (model.predict(x_test) > 0.15)
```

We now predict heart disease in individuals whose data leads to a final neuron activation of 0.15 or more.  We may catch some of the patients who would have fallen through the cracks using the stricter cutoff of 0.5.  Indeed, after this change we obtain the following confusion matrix, specificity, sensitivity, accuracy:

```
[[17 10]
 [ 1 33]]
specificity :  0.7674418604651163
sensitivity :  0.9444444444444444
accuracy :  0.819672131147541
```

Many more false positives to be sure, but only one false negative.  

Another way to decrease false negatives is to create an ensemble voting model out of many simpler models, and to require not just a majority vote, but a supermajority vote, to declare a negative result.



# Voting Ensemble
A popular technique in modern machine learning is to combine several models into a single model which uses majority vote.  We'll carry this out here with the 7 models defined above.  In more detail, we'll make a model `vote_model` which takes an input `x` and feeds it into our 7 models, counts the predictions (0 or 1), and returns 1 if (say) 4 of our 7 models predicted 1.  

This gives us another way to decrease the number of false negatives:  simply change the threshold so that `vote_model` predicts 1 if 3 (or 2, or 1) of our 7 models predicted 1.  Of course this will increase the number of false positives, but for medical diagnosis this is a welcome tradeoff.

Our implementation is a bit ad-hoc because scikit-learn models and keras models return their predictions in slightly different formats.  
```python
votes = lin_model.predict(x_test) + svm_model.predict(x_test) + nb_model.predict(x_test) \
        + forest_model.predict(x_test) + tree_model.predict(x_test) + knn_model.predict(x_test) \
        + ((nn_model.predict(x_test)>0.5).T)[0].astype(float)
```

`votes` is now a numpy array populated with integers 0-7 depending on how many votes the corresponding element of the test set got.  Next we can test our vote results against our known test labels:

```python
conf_mat = confusion_matrix((y_test.values == 1.0),  (votes >= 4))
total = sum(sum(conf_mat))
sensitivity = conf_mat[0, 0]/(conf_mat[0, 0] + conf_mat[1, 0])
specificity = conf_mat[1, 1]/(conf_mat[1, 1] + conf_mat[0, 1])
accuracy = (conf_mat[0, 0] + conf_mat[1, 1])/total

print("Statistics for voting classifier, where simple majority rules:\n")
print(conf_mat)
print('specificity : ', specificity)
print('sensitivity : ', sensitivity)
print('accuracy : ', accuracy)
```
 
 ```
 Statistics for voting classifier, where simple majority rules:

[[23  4]
 [ 5 29]]
specificity :  0.8787878787878788
sensitivity :  0.8214285714285714
accuracy :  0.8524590163934426
```

This model gives 5 false negatives - quite high.  Let's back it off a bit by changing the vote threshold:
```python
conf_mat = confusion_matrix((y_test.values == 1.0),  (votes >= 2))
total = sum(sum(conf_mat))
sensitivity = conf_mat[0, 0]/(conf_mat[0, 0] + conf_mat[1, 0])
specificity = conf_mat[1, 1]/(conf_mat[1, 1] + conf_mat[0, 1])
accuracy = (conf_mat[0, 0] + conf_mat[1, 1])/total

print("Statistics for voting classifier, where it only takes 2 positive votes (out of 7 votes) to declare "
      "a positive result:\n")
print(conf_mat)
print('specificity : ', specificity)
print('sensitivity : ', sensitivity)
print('accuracy : ', accuracy)
```

```
Statistics for voting classifier, where it only takes 2 positive votes (out of 7 votes) to declare a positive result:

[[21  6]
 [ 2 32]]
specificity :  0.8421052631578947
sensitivity :  0.9130434782608695
accuracy :  0.8688524590163934
```

Now we're down to 2 false negatives - much better for this sort of application.  


# Closing Remarks:
While looking into this dataset I noticed that the 'target' variable may have been entered incorrectly.  The 'target' variable is supposed to be 0 if there's no heart disease and 1 if there is heart disease.  However, looking at the following heat map of the data set suggests that it might be the other way around:

 ![Heatmap](/Images/heatmap.png)
 
 We see that 'target' is negatively correlated with age, cholesterol level, being male, ... All things which one would think make heart disease more likely, not less.  I decided to hold this until the conclusion because it doesn't change *how* one would carry out this analysis; it simply changes the model one arrives at.  
 
After looking through some kaggle kernels on this problem, I noticed that many models achieved test accuracy of .885.  This number was consistent across:  Random forest, decision tree, k-nearest neighbor, SVM, logistic regression, deep and shallow NN, etc.  The fact that so many classifiers got to the same 88.5% accuracy suggests that the Bayes error for this task may well be close to 11.5%.  

Finally, there is a lot of tuning to be done here.  Each scikit-learn model has tons of parameters to tune, and we've mostly opted for the default values.  Our Keras model could definitely be improved as well.  We could also reduce false negatives by first reducing them on each individual model, and then using a voting ensemble which requires a supermajority to return a positive.

